{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30481</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "30481      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "30481       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "30481         0         0         0         0         0  \n",
       "\n",
       "[1 rows x 785 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train['label']\n",
    "X_train = train.drop(columns=['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2. Check for null and missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for images with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values in the train and test dataset so we can go ahead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "test = test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4. Reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape(-1, 28, 28, 1)\n",
    "test = test.values.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tain and test images (28px x 28px) hve been stock into pandas dataframe as 1D vector of 784 values. We need to reshape the data to 28 x 28 x 1 3D matrices.\n",
    "\n",
    "Keras requires an extra dimension in the end which correspond to channels. MNIST images are gray scaled so they use only one channel. For RGB images, there are 3 channels so we would have reshaped 784px to 28 x 28 x 3 3D matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    5. Label encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode labels to one hot vectors (ex: 2 -> [0, 0, 1, 0, 0, 0, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    4\n",
       "4    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "Y_train = to_categorical(Y_train, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    6. Split training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15e7caabf50>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[2][:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model.add(Conv2D(...))** adds a convolutional layer to the model.\n",
    "    \n",
    "- La convolución es una operación fundamental en el procesamiento de imágenes que permite extraer características locales.\n",
    "\n",
    "**filters=32** indica que la capa tendrá 32 filtros (también conocidos como kernels).\n",
    "\n",
    "- Cada filtro aprenderá a detectar diferentes patrones en la entrada.\n",
    "\n",
    "**kernel_size=(5,5)** expecifica el tamaño del kernel o filtro de convolución.\n",
    "\n",
    "- En este caso, el kernel es una matriz 5x5 que se desplaza sobre la entrada para realizar la convolución.\n",
    "\n",
    "**padding='Same'** controla cómo manejar el borde de la imagen.\n",
    "\n",
    "- 'Same' significa que el borde se llena con ceros para mantener el tamaño de la entrada después de la convolución.\n",
    "\n",
    "**activation='relu'** indica que se aplicará la función de activación ReLU (Rectified Linear Unit) después de realizar la convolución.\n",
    "\n",
    "- ReLU es comúnmente utilizado para introducir no linealidades en la red.\n",
    "\n",
    "**input_shape=(28,28,1)** especifica la forma de la entrada a la capa.\n",
    "\n",
    "- En este caso, se espera que la entrada sea una imagen de 28x28 píxeles con un solo canal de color (escala de grises). El 1 en la última dimension indica que hay un solo canal.\n",
    "\n",
    "**model.add(MaxPool2D(pool_size=(2,2)))**\n",
    "\n",
    "- **MaxPool2D** es una capa de reducción de muestreo o pooling en una red neuronal convolucional.\n",
    "\n",
    "- **pool_size=(2,2)** especifica el tamaño de la ventana sobre la cual se realizará el muestreo máximo. En este caso es una ventana de 2x2 píxeles.\n",
    "\n",
    "- El propósito de esta capa es reducir el tamaño espacial de la representación para disminuir la cantidad de parámetros y cálculos en la red, preservando las características más importantes aprendidas por las capas de convolución.\n",
    "\n",
    "- El muestreo máximo toma el valor máximo de cada ventana de la imagen y lo conserva, descartando el resto.\n",
    "\n",
    "**model.add(Dropout(0.25))**\n",
    "\n",
    "- **Dropout** es una técnica de regularización utilizada para reducir el sobreajuste (overfitting) en modelos de redes neuronales.\n",
    "\n",
    "- **0.25** indica la fracción de unidades de la red que se desactivarán aleatoriamente durante el entrenamiento.\n",
    "\n",
    "- Durante el entrenamiento, Dropout desactiva aleatoriamente una fracción de las neuronas de la capa anterior, lo que fuerza a la red a aprender características de manera más robusta, evitando que se especialice demasiado en ciertas características de los datos de entrenamiento.\n",
    "\n",
    "- Esto ayuda a mejorar la generalización del modelo a nuevos datos y a reducir el riesgo de sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\noemi\\miniconda3\\envs\\project\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\noemi\\miniconda3\\envs\\project\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), padding='Same', activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), padding='Same', activation='relu', input_shape=(28,28,1)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2. Set optimizer and annealer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the layers added to the model, we need to set up a score function, a loss function and an optimisation algorithm.\n",
    "\n",
    "We define the loss function to measure how poorly our model performs on images with known labels. It is the error rate between the observed labels and the predicted ones. We use a specific form for categorical classifications (>2 classes) called the \"categorical_crossentropy\".\n",
    "\n",
    "The most important function is the optimizer. This function will iteratively improve parameters (filters kernel values, weights and bias of neurons ...) in order to minimise the loss.\n",
    "\n",
    "I choosed RMSprop (with default values), it is a very effective optimizer. The RMSProp update adjusts the Adagrad method in a very simple way in an attempt to reduce its aggressive, monotonically decreasing learning rate. We could also have used Stochastic Gradient Descent ('sgd') optimizer, but it is slower than RMSprop.\n",
    "\n",
    "The metric function \"accuracy\" is used is to evaluate the performance of our model. This metric function is similar to the loss function, except that the results from the metric evaluation are not used when training the model (only for evaluation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30 # Turn epochs to 30 to get 0.9967 accuracy\n",
    "batch_size = 86"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3. Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "440/440 [==============================] - 13s 29ms/step - loss: 0.0192 - accuracy: 0.9949 - val_loss: 0.0446 - val_accuracy: 0.9936\n",
      "Epoch 2/30\n",
      "440/440 [==============================] - 13s 30ms/step - loss: 0.0194 - accuracy: 0.9952 - val_loss: 0.0479 - val_accuracy: 0.9926\n",
      "Epoch 3/30\n",
      "440/440 [==============================] - 14s 31ms/step - loss: 0.0166 - accuracy: 0.9961 - val_loss: 0.0512 - val_accuracy: 0.9910\n",
      "Epoch 4/30\n",
      "440/440 [==============================] - 14s 31ms/step - loss: 0.0186 - accuracy: 0.9955 - val_loss: 0.0408 - val_accuracy: 0.9933\n",
      "Epoch 5/30\n",
      "440/440 [==============================] - 14s 32ms/step - loss: 0.0174 - accuracy: 0.9960 - val_loss: 0.0598 - val_accuracy: 0.9914\n",
      "Epoch 6/30\n",
      "440/440 [==============================] - 14s 32ms/step - loss: 0.0190 - accuracy: 0.9957 - val_loss: 0.0507 - val_accuracy: 0.9924\n",
      "Epoch 7/30\n",
      "440/440 [==============================] - 15s 33ms/step - loss: 0.0185 - accuracy: 0.9951 - val_loss: 0.0289 - val_accuracy: 0.9921\n",
      "Epoch 8/30\n",
      "440/440 [==============================] - 16s 36ms/step - loss: 0.0218 - accuracy: 0.9951 - val_loss: 0.0584 - val_accuracy: 0.9933\n",
      "Epoch 9/30\n",
      "440/440 [==============================] - 17s 38ms/step - loss: 0.0192 - accuracy: 0.9954 - val_loss: 0.0304 - val_accuracy: 0.9943\n",
      "Epoch 10/30\n",
      "440/440 [==============================] - 17s 38ms/step - loss: 0.0187 - accuracy: 0.9957 - val_loss: 0.0400 - val_accuracy: 0.9943\n",
      "Epoch 11/30\n",
      "440/440 [==============================] - 17s 38ms/step - loss: 0.0195 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9926\n",
      "Epoch 12/30\n",
      "440/440 [==============================] - 16s 37ms/step - loss: 0.0201 - accuracy: 0.9957 - val_loss: 0.0322 - val_accuracy: 0.9936\n",
      "Epoch 13/30\n",
      "440/440 [==============================] - 16s 37ms/step - loss: 0.0180 - accuracy: 0.9956 - val_loss: 0.0753 - val_accuracy: 0.9895\n",
      "Epoch 14/30\n",
      "440/440 [==============================] - 17s 38ms/step - loss: 0.0206 - accuracy: 0.9955 - val_loss: 0.0433 - val_accuracy: 0.9929\n",
      "Epoch 15/30\n",
      "440/440 [==============================] - 17s 38ms/step - loss: 0.0204 - accuracy: 0.9960 - val_loss: 0.0668 - val_accuracy: 0.9910\n",
      "Epoch 16/30\n",
      "440/440 [==============================] - 17s 38ms/step - loss: 0.0196 - accuracy: 0.9960 - val_loss: 0.0456 - val_accuracy: 0.9943\n",
      "Epoch 17/30\n",
      "440/440 [==============================] - 17s 38ms/step - loss: 0.0240 - accuracy: 0.9956 - val_loss: 0.0347 - val_accuracy: 0.9938\n",
      "Epoch 18/30\n",
      "440/440 [==============================] - 17s 38ms/step - loss: 0.0183 - accuracy: 0.9959 - val_loss: 0.0616 - val_accuracy: 0.9917\n",
      "Epoch 19/30\n",
      "440/440 [==============================] - 17s 38ms/step - loss: 0.0189 - accuracy: 0.9959 - val_loss: 0.0609 - val_accuracy: 0.9895\n",
      "Epoch 20/30\n",
      "440/440 [==============================] - 17s 38ms/step - loss: 0.0197 - accuracy: 0.9959 - val_loss: 0.0678 - val_accuracy: 0.9931\n",
      "Epoch 21/30\n",
      "440/440 [==============================] - 17s 38ms/step - loss: 0.0190 - accuracy: 0.9961 - val_loss: 0.0453 - val_accuracy: 0.9933\n",
      "Epoch 22/30\n",
      "440/440 [==============================] - 17s 38ms/step - loss: 0.0195 - accuracy: 0.9958 - val_loss: 0.0538 - val_accuracy: 0.9929\n",
      "Epoch 23/30\n",
      "440/440 [==============================] - 17s 38ms/step - loss: 0.0194 - accuracy: 0.9960 - val_loss: 0.0425 - val_accuracy: 0.9924\n",
      "Epoch 24/30\n",
      "440/440 [==============================] - 17s 38ms/step - loss: 0.0206 - accuracy: 0.9957 - val_loss: 0.0402 - val_accuracy: 0.9938\n",
      "Epoch 25/30\n",
      "440/440 [==============================] - 17s 38ms/step - loss: 0.0220 - accuracy: 0.9955 - val_loss: 0.0617 - val_accuracy: 0.9938\n",
      "Epoch 26/30\n",
      "440/440 [==============================] - 17s 38ms/step - loss: 0.0215 - accuracy: 0.9960 - val_loss: 0.0346 - val_accuracy: 0.9933\n",
      "Epoch 27/30\n",
      "440/440 [==============================] - 17s 38ms/step - loss: 0.0224 - accuracy: 0.9962 - val_loss: 0.0651 - val_accuracy: 0.9943\n",
      "Epoch 28/30\n",
      "440/440 [==============================] - 17s 38ms/step - loss: 0.0194 - accuracy: 0.9956 - val_loss: 0.0553 - val_accuracy: 0.9924\n",
      "Epoch 29/30\n",
      "440/440 [==============================] - 17s 38ms/step - loss: 0.0233 - accuracy: 0.9958 - val_loss: 0.0640 - val_accuracy: 0.9919\n",
      "Epoch 30/30\n",
      "440/440 [==============================] - 17s 38ms/step - loss: 0.0215 - accuracy: 0.9957 - val_loss: 0.0434 - val_accuracy: 0.9912\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, validation_data = (X_val, Y_val), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=15,\n",
    "    zoom_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noemi\\AppData\\Local\\Temp\\ipykernel_19864\\2118646199.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/439 [============================>.] - ETA: 0s - loss: 0.1852 - accuracy: 0.9520WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 14s 31ms/step - loss: 0.1849 - accuracy: 0.9520 - val_loss: 0.0440 - val_accuracy: 0.9910 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.1300 - accuracy: 0.9662WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 14s 32ms/step - loss: 0.1300 - accuracy: 0.9662 - val_loss: 0.0306 - val_accuracy: 0.9924 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.1103 - accuracy: 0.9701WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 14s 33ms/step - loss: 0.1103 - accuracy: 0.9701 - val_loss: 0.0363 - val_accuracy: 0.9912 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.1050 - accuracy: 0.9734WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 14s 32ms/step - loss: 0.1050 - accuracy: 0.9734 - val_loss: 0.0247 - val_accuracy: 0.9933 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.0994 - accuracy: 0.9746WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 15s 33ms/step - loss: 0.0994 - accuracy: 0.9746 - val_loss: 0.0399 - val_accuracy: 0.9902 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.0927 - accuracy: 0.9754WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 15s 34ms/step - loss: 0.0927 - accuracy: 0.9754 - val_loss: 0.0305 - val_accuracy: 0.9910 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.0974 - accuracy: 0.9753WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 16s 36ms/step - loss: 0.0974 - accuracy: 0.9753 - val_loss: 0.0237 - val_accuracy: 0.9938 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.0934 - accuracy: 0.9761WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 17s 38ms/step - loss: 0.0934 - accuracy: 0.9761 - val_loss: 0.0310 - val_accuracy: 0.9914 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.0898 - accuracy: 0.9772WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 17s 38ms/step - loss: 0.0898 - accuracy: 0.9772 - val_loss: 0.0342 - val_accuracy: 0.9898 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.0930 - accuracy: 0.9767WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 17s 38ms/step - loss: 0.0930 - accuracy: 0.9767 - val_loss: 0.0342 - val_accuracy: 0.9921 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.0980 - accuracy: 0.9765WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 17s 38ms/step - loss: 0.0980 - accuracy: 0.9765 - val_loss: 0.0345 - val_accuracy: 0.9902 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "438/439 [============================>.] - ETA: 0s - loss: 0.0931 - accuracy: 0.9766WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 17s 39ms/step - loss: 0.0929 - accuracy: 0.9766 - val_loss: 0.0417 - val_accuracy: 0.9893 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.0932 - accuracy: 0.9769WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 18s 40ms/step - loss: 0.0932 - accuracy: 0.9769 - val_loss: 0.0313 - val_accuracy: 0.9914 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "438/439 [============================>.] - ETA: 0s - loss: 0.0927 - accuracy: 0.9776WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 18s 41ms/step - loss: 0.0930 - accuracy: 0.9776 - val_loss: 0.0333 - val_accuracy: 0.9926 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.0938 - accuracy: 0.9783WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 19s 43ms/step - loss: 0.0938 - accuracy: 0.9783 - val_loss: 0.0320 - val_accuracy: 0.9919 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "438/439 [============================>.] - ETA: 0s - loss: 0.0989 - accuracy: 0.9767WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 18s 42ms/step - loss: 0.0988 - accuracy: 0.9768 - val_loss: 0.0314 - val_accuracy: 0.9919 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.0948 - accuracy: 0.9766WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 18s 42ms/step - loss: 0.0948 - accuracy: 0.9766 - val_loss: 0.0255 - val_accuracy: 0.9924 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "438/439 [============================>.] - ETA: 0s - loss: 0.0973 - accuracy: 0.9766WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 18s 42ms/step - loss: 0.0974 - accuracy: 0.9765 - val_loss: 0.0235 - val_accuracy: 0.9929 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "438/439 [============================>.] - ETA: 0s - loss: 0.0967 - accuracy: 0.9765WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 18s 42ms/step - loss: 0.0968 - accuracy: 0.9765 - val_loss: 0.0300 - val_accuracy: 0.9914 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "438/439 [============================>.] - ETA: 0s - loss: 0.0973 - accuracy: 0.9765WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 18s 41ms/step - loss: 0.0973 - accuracy: 0.9765 - val_loss: 0.0337 - val_accuracy: 0.9905 - lr: 0.0010\n",
      "Epoch 21/30\n",
      "438/439 [============================>.] - ETA: 0s - loss: 0.1010 - accuracy: 0.9762WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 18s 41ms/step - loss: 0.1009 - accuracy: 0.9762 - val_loss: 0.0530 - val_accuracy: 0.9902 - lr: 0.0010\n",
      "Epoch 22/30\n",
      "438/439 [============================>.] - ETA: 0s - loss: 0.0990 - accuracy: 0.9767WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 18s 41ms/step - loss: 0.0989 - accuracy: 0.9768 - val_loss: 0.0453 - val_accuracy: 0.9902 - lr: 0.0010\n",
      "Epoch 23/30\n",
      "438/439 [============================>.] - ETA: 0s - loss: 0.0975 - accuracy: 0.9766WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 18s 42ms/step - loss: 0.0974 - accuracy: 0.9766 - val_loss: 0.0290 - val_accuracy: 0.9921 - lr: 0.0010\n",
      "Epoch 24/30\n",
      "438/439 [============================>.] - ETA: 0s - loss: 0.0974 - accuracy: 0.9771WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 18s 42ms/step - loss: 0.0977 - accuracy: 0.9771 - val_loss: 0.0430 - val_accuracy: 0.9917 - lr: 0.0010\n",
      "Epoch 25/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.0918 - accuracy: 0.9788WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 19s 43ms/step - loss: 0.0918 - accuracy: 0.9788 - val_loss: 0.0472 - val_accuracy: 0.9907 - lr: 0.0010\n",
      "Epoch 26/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.1050 - accuracy: 0.9761WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 18s 42ms/step - loss: 0.1050 - accuracy: 0.9761 - val_loss: 0.0527 - val_accuracy: 0.9888 - lr: 0.0010\n",
      "Epoch 27/30\n",
      "438/439 [============================>.] - ETA: 0s - loss: 0.1048 - accuracy: 0.9764WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 18s 41ms/step - loss: 0.1046 - accuracy: 0.9765 - val_loss: 0.0616 - val_accuracy: 0.9890 - lr: 0.0010\n",
      "Epoch 28/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.1134 - accuracy: 0.9748WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 18s 41ms/step - loss: 0.1134 - accuracy: 0.9748 - val_loss: 0.0472 - val_accuracy: 0.9902 - lr: 0.0010\n",
      "Epoch 29/30\n",
      "438/439 [============================>.] - ETA: 0s - loss: 0.1043 - accuracy: 0.9755WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 18s 41ms/step - loss: 0.1043 - accuracy: 0.9755 - val_loss: 0.0452 - val_accuracy: 0.9907 - lr: 0.0010\n",
      "Epoch 30/30\n",
      "439/439 [==============================] - ETA: 0s - loss: 0.1061 - accuracy: 0.9753WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 [==============================] - 18s 41ms/step - loss: 0.1061 - accuracy: 0.9753 - val_loss: 0.0430 - val_accuracy: 0.9921 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                              epochs=epochs, validation_data=(X_val, Y_val),\n",
    "                              verbose=1, steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                              callbacks=[learning_rate_reduction])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
